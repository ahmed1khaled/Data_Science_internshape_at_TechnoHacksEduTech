{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T12:43:41.357664Z","iopub.execute_input":"2023-10-01T12:43:41.357986Z","iopub.status.idle":"2023-10-01T12:43:41.659969Z","shell.execute_reply.started":"2023-10-01T12:43:41.357959Z","shell.execute_reply":"2023-10-01T12:43:41.659094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RepeatedKFold\nfrom sklearn.ensemble import GradientBoostingRegressor, VotingRegressor\nfrom sklearn.linear_model import LassoCV, RidgeCV, LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n%matplotlib inline\nsns.set(rc={'figure.figsize': [10, 10]}, font_scale=1.2)\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:38:48.853872Z","iopub.execute_input":"2023-10-02T10:38:48.854200Z","iopub.status.idle":"2023-10-02T10:38:48.863889Z","shell.execute_reply.started":"2023-10-02T10:38:48.854174Z","shell.execute_reply":"2023-10-02T10:38:48.862881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:38.716625Z","iopub.execute_input":"2023-10-02T10:31:38.717192Z","iopub.status.idle":"2023-10-02T10:31:38.847502Z","shell.execute_reply.started":"2023-10-02T10:31:38.717167Z","shell.execute_reply":"2023-10-02T10:31:38.846634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:39.797771Z","iopub.execute_input":"2023-10-02T10:31:39.798435Z","iopub.status.idle":"2023-10-02T10:31:39.821187Z","shell.execute_reply.started":"2023-10-02T10:31:39.798397Z","shell.execute_reply":"2023-10-02T10:31:39.820203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.columns:\n    print(col + '\\n------')\n    print(df[col].value_counts())\n    print('---------------------')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:40.018359Z","iopub.execute_input":"2023-10-02T10:31:40.018664Z","iopub.status.idle":"2023-10-02T10:31:40.050854Z","shell.execute_reply.started":"2023-10-02T10:31:40.018640Z","shell.execute_reply":"2023-10-02T10:31:40.049942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:40.360547Z","iopub.execute_input":"2023-10-02T10:31:40.361079Z","iopub.status.idle":"2023-10-02T10:31:40.370517Z","shell.execute_reply.started":"2023-10-02T10:31:40.361054Z","shell.execute_reply":"2023-10-02T10:31:40.369572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:40.658466Z","iopub.execute_input":"2023-10-02T10:31:40.658751Z","iopub.status.idle":"2023-10-02T10:31:40.719403Z","shell.execute_reply.started":"2023-10-02T10:31:40.658727Z","shell.execute_reply":"2023-10-02T10:31:40.718436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:40.983678Z","iopub.execute_input":"2023-10-02T10:31:40.984638Z","iopub.status.idle":"2023-10-02T10:31:40.991297Z","shell.execute_reply.started":"2023-10-02T10:31:40.984593Z","shell.execute_reply":"2023-10-02T10:31:40.990367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstand= StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:41.290757Z","iopub.execute_input":"2023-10-02T10:31:41.291080Z","iopub.status.idle":"2023-10-02T10:31:41.295800Z","shell.execute_reply.started":"2023-10-02T10:31:41.291052Z","shell.execute_reply":"2023-10-02T10:31:41.294865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor column in ['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n       'lat', 'long', 'sqft_living15', 'sqft_lot15']:\n    df[column] = stand.fit_transform(df[column].values.reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:42.454466Z","iopub.execute_input":"2023-10-02T10:31:42.454778Z","iopub.status.idle":"2023-10-02T10:31:42.480429Z","shell.execute_reply.started":"2023-10-02T10:31:42.454754Z","shell.execute_reply":"2023-10-02T10:31:42.479610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=df.drop('date', axis = 1)\nplt.figure(figsize=(16,16))\nsns.heatmap(df1.corr(), annot=True, fmt=\".1f\");","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:43.421314Z","iopub.execute_input":"2023-10-02T10:31:43.421664Z","iopub.status.idle":"2023-10-02T10:31:44.862251Z","shell.execute_reply.started":"2023-10-02T10:31:43.421640Z","shell.execute_reply":"2023-10-02T10:31:44.861449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's split the dataset\nx = df1.drop('price', axis=1)\ny = df1[['price']]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:31:44.863530Z","iopub.execute_input":"2023-10-02T10:31:44.863824Z","iopub.status.idle":"2023-10-02T10:31:44.874433Z","shell.execute_reply.started":"2023-10-02T10:31:44.863797Z","shell.execute_reply":"2023-10-02T10:31:44.873317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Modeling\n#It's regression problem because the target variable ('price') is continuous variable.\n\ndef fitting_models(x, y, cv=3):\n    names = []\n    scores_mse = []\n    scores_rmse = []\n    scores_r2 = []\n    \n    regressors = [\n        ('LinearRegression', LinearRegression()),\n        ('DecisionTreeRegressor', DecisionTreeRegressor()),\n        ('RandomForestRegressor', RandomForestRegressor()),\n        ('GradientBoostingRegressor', GradientBoostingRegressor()),\n        ('KNeighborsRegressor', KNeighborsRegressor()),\n        ('SVR', SVR()),\n        ('Lasso', Lasso()),\n        ('Ridge', Ridge())\n    ]\n    \n    for model in regressors:\n        names.append(model[0])\n        \n        cv_results = cross_validate(model[1], x, y, cv=cv, scoring=('r2', 'neg_mean_squared_error'))\n\n        mse = -cv_results['test_neg_mean_squared_error'].mean()\n        r2_score = cv_results['test_r2'].mean()\n        rmse = np.sqrt(mse)\n        \n        scores_mse.append(mse)\n        scores_rmse.append(rmse)\n        scores_r2.append(r2_score)\n        \n        print(f\"Model's name: {model[0]}: MSE -> {mse}; RMSE -> {rmse}; 'R2' -> {r2_score}\")\n        \n    \n    data = pd.DataFrame({\n        'names':names,\n        'mse':scores_mse,\n        'rmse':scores_rmse,\n        'r2':scores_r2\n    })\n    \n    return data\n\ndata = fitting_models(x, y)\n\nprint(data)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T10:38:53.914973Z","iopub.execute_input":"2023-10-02T10:38:53.915460Z","iopub.status.idle":"2023-10-02T10:40:19.829632Z","shell.execute_reply.started":"2023-10-02T10:38:53.915416Z","shell.execute_reply":"2023-10-02T10:40:19.828423Z"},"trusted":true},"execution_count":null,"outputs":[]}]}